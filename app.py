
import os
import json
import time
import logging
from pathlib import Path

import streamlit as st
import pandas as pd
import numpy as np
import faiss
from dotenv import load_dotenv
import google.generativeai as genai

# ------------------ CONFIG ------------------ #
EMBED_MODEL = "models/embedding-001"      # Gemini embeddingãƒ¢ãƒ‡ãƒ« (Flashã¨äº’æ›)
CHAT_MODEL  = "models/gemini-1.5-flash-latest"
FAISS_THRESHOLD = 0.80                    # FAQãƒãƒƒãƒåˆ¤å®šç”¨

LOG_DIR = Path("logs")
LOG_DIR.mkdir(exist_ok=True)
CHAT_LOG_FILE = LOG_DIR / "chat_logs.jsonl"
UNANSWERED_FILE = LOG_DIR / "unanswered.jsonl"

st.set_page_config(page_title="AIå…ˆè¼© FAQ Bot", page_icon="ğŸ¤–", layout="centered")
st.title("ğŸ“ AIå…ˆè¼© â€“ FAQãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

# ------------------  UTIL ------------------ #
def append_jsonl(path: Path, data: dict) -> None:
    """JSON Lines å½¢å¼ã§1è¡Œè¿½è¨˜"""
    with path.open("a", encoding="utf-8") as f:
        f.write(json.dumps(data, ensure_ascii=False) + "\n")

# ------------------  LOAD ENV ------------------ #
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    st.error("`.env` ã« GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()
genai.configure(api_key=GOOGLE_API_KEY)

# ------------------  LOAD FAQ & BUILD INDEX ------------------ #
@st.cache_resource(show_spinner="FAQ ã‚’èª­ã¿è¾¼ã¿ä¸­ ...")  # å†èµ·å‹•ã¾ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def load_faq_index(csv_path: str = "faq.csv"):
    if not Path(csv_path).exists():
        st.error(f"{csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚app.py ã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    df = pd.read_csv(csv_path)
    if not {"question", "answer"}.issubset(df.columns):
        st.error("`faq.csv` ã«ã¯ 'question' ã¨ 'answer' ã®åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        st.stop()

    # Embedding
    embeddings = []
    for q in df["question"].tolist():
        try:
            emb = genai.embed_content(model=EMBED_MODEL, content=q, task_type="retrieval_query")["embedding"]
            embeddings.append(emb)
        except Exception as e:
            st.error(f"Embedding å¤±æ•—: {e}")
            st.stop()

    embeddings = np.array(embeddings).astype("float32")
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)

    return df, index, embeddings

faq_df, faq_index, faq_embeddings = load_faq_index()

# ------------------  SIDEBAR ------------------ #
with st.sidebar:
    st.subheader("ğŸ“„ FAQ ãƒ‡ãƒ¼ã‚¿")
    st.write(f"ä»¶æ•°: {len(faq_df)}")
    if st.button("FAQ å…ˆé ­5ä»¶ã‚’è¦‹ã‚‹"):
        st.dataframe(faq_df.head())

    st.markdown("---")
    st.markdown("**é–¾å€¤ (é¡ä¼¼åº¦)**")
    FAISS_THRESHOLD = st.slider("FAQ ãƒãƒƒãƒé–¾å€¤", 0.0, 1.0, FAISS_THRESHOLD, 0.01)

# ------------------  CHAT LOOP ------------------ #
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Render previous messages
for role, msg in st.session_state.chat_history:
    box = st.chat_message(role)
    box.markdown(msg)

# User input
if prompt := st.chat_input("è³ªå•ã‚’ã©ã†ã"):
    st.session_state.chat_history.append(("user", prompt))
    user_box = st.chat_message("user")
    user_box.markdown(prompt)

    # Embedding & search
    try:
        user_emb = genai.embed_content(model=EMBED_MODEL, content=prompt, task_type="retrieval_query")["embedding"]
    except Exception as e:
        st.error(f"Embedding å¤±æ•—: {e}")
        st.stop()

    D, I = faq_index.search(np.array([user_emb]).astype("float32"), k=1)
    similarity = 1 - D[0][0] / 2  # L2->cos é©å½“å¤‰æ› (0~1ãã‚‰ã„ã®ç›®å®‰)

    answered_by_faq = similarity >= FAISS_THRESHOLD
    response = ""
    source_question = ""
    if answered_by_faq:
        source_question = faq_df.iloc[I[0][0]]["question"]
        response = faq_df.iloc[I[0][0]]["answer"]
    else:
        # æ¤œç´¢çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ Gemini ã«æŠ•ã’ã‚‹
        context = ""
        if similarity > 0.2:  # ä¸€å¿œè¿‘ã„ã‚‚ã®ãŒã‚ã‚Œã°
            context = (
                f"å‚è€ƒã«ãªã‚Šãã†ãª FAQ:\n"
                f"Q: {faq_df.iloc[I[0][0]]['question']}\n"
                f"A: {faq_df.iloc[I[0][0]]['answer']}\n---"
            )

        system_prompt = (
            'ã‚ãªãŸã¯å¤§å­¦ã®å…ˆè¼©ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ "AIå…ˆè¼©" ã§ã™ã€‚'
            'ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§ç«¯çš„ã‹ã¤ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚'
        )
        full_prompt = f"{context}\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}"

        try:
            gen_response = genai.generate_content(
                model=CHAT_MODEL,
                contents=[
                    {"role": "system", "parts": [{"text": system_prompt}]},
                    {"role": "user",   "parts": [{"text": full_prompt}]},
                ],
                safety_settings={
                    "category": "HARM_CATEGORY_DANGEROUS",
                    "threshold": "BLOCK_NONE",
                },
            )
            response = gen_response.candidates[0].content.parts[0].text
        except Exception as e:
            response = (
                "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
                "å¾Œã§ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            )
            logging.exception(e)

    # Display assistant response
    assistant_box = st.chat_message("assistant")
    assistant_box.markdown(response)
    st.session_state.chat_history.append(("assistant", response))

    # Caption for debug
    assistant_box.caption(f"FAQ é¡ä¼¼åº¦: {similarity:.2f} / ãƒãƒƒãƒ: {answered_by_faq}")

    # --- JSON ã«å®‰å…¨ã«å¤‰æ›ã§ãã‚‹ã‚ˆã†ã«ä¿é™º ------------------
if not isinstance(response, str):
    response = str(response)
if not isinstance(similarity, float):
    similarity = float(similarity)
# -----------------------------------------------------------
    # Logging
    log_entry = {
        "ts": time.time(),
        "question": prompt,
        "answered_by_faq": answered_by_faq,
        "similarity": similarity,
        "faq_question": source_question,
        "answer": response,
    }
    append_jsonl(CHAT_LOG_FILE, log_entry)

    if not answered_by_faq:
        append_jsonl(UNANSWERED_FILE, log_entry)

        st.caption(f"ï¼ˆé¡ä¼¼åº¦: {top_similarity:.2f}, æœªå›ç­”: {is_unanswered}ï¼‰")
