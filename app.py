
import streamlit as st
import google.generativeai as genai
import pandas as pd
import os
from dotenv import load_dotenv
import faiss
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import datetime

# --- 1. ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()
GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GEMINI_API_KEY:
    st.error("ã‚¨ãƒ©ãƒ¼: .env ãƒ•ã‚¡ã‚¤ãƒ«ã« GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)

# --- 2. Gemini ãƒ¢ãƒ‡ãƒ«ã®è¨­å®š ---
GENERATION_MODEL = "gemini-1.5-flash"
EMBEDDING_MODEL = "models/text-embedding-004"

# --- 3. FAQãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆ ---
FAQ_FILE = "faq.csv"
FAISS_THRESHOLD = 0.8  # å›ç­”ãªã—ã¨åˆ¤æ–­ã™ã‚‹é¡ä¼¼åº¦é–¾å€¤

@st.cache_resource
def load_faq_and_create_faiss_index():
    try:
        df_faq = pd.read_csv(FAQ_FILE)
        st.success(f"{FAQ_FILE} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚è³ªå•æ•°: {len(df_faq)}")
    except FileNotFoundError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: {FAQ_FILE} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚app.py ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: {FAQ_FILE} ã®èª­ã¿è¾¼ã¿ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

    questions = df_faq["question"].tolist()
    answers = df_faq["answer"].tolist()

    st.write("FAQã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆä¸­...")
    embeddings = []
    try:
        # ãƒãƒƒãƒå‡¦ç†ã§ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”Ÿæˆ
        for i in range(0, len(questions), 10):
            batch = questions[i : i + 10]
            response = genai.embed_content(
                model=EMBEDDING_MODEL,
                content=batch,
                task_type="RETRIEVAL_QUERY"
            )
            batch_embeds = [item["embedding"] if isinstance(item, dict) else item for item in response]
            embeddings.extend(batch_embeds)
            st.write(f"  - {min(i + 10, len(questions))} / {len(questions)} ä»¶ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ...")

        st.success("FAQã®åŸ‹ã‚è¾¼ã¿ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        embeddings = np.array(embeddings).astype('float32')

        dimension = embeddings.shape[1]
        index = faiss.IndexFlatL2(dimension)
        index.add(embeddings)

        st.success("FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
        return index, questions, answers

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã¾ãŸã¯FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

faiss_index, faq_questions, faq_answers = load_faq_and_create_faiss_index()

# --- 4. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ ---
CHAT_LOG_FILE = "chat_logs.csv"
UNANSWERED_LOG_FILE = "unanswered.csv"

def initialize_log_files():
    if not os.path.exists(CHAT_LOG_FILE):
        pd.DataFrame(columns=["timestamp", "user_question", "bot_answer", "is_unanswered", "source_faq_question"]).to_csv(CHAT_LOG_FILE, index=False)
    if not os.path.exists(UNANSWERED_LOG_FILE):
        pd.DataFrame(columns=["timestamp", "user_question"]).to_csv(UNANSWERED_LOG_FILE, index=False)

initialize_log_files()

def append_log(file_path, data):
    df = pd.DataFrame([data])
    df.to_csv(file_path, mode='a', header=not os.path.exists(file_path) or pd.read_csv(file_path).empty, index=False)

# --- 5. Streamlit UI ã¨ãƒãƒ£ãƒƒãƒˆãƒ­ã‚¸ãƒƒã‚¯ ---
st.set_page_config(page_title="AIå…ˆè¼©", page_icon="ğŸ“")
st.title("ğŸ“ AIå…ˆè¼©")
st.caption("å±¥ä¿®ç™»éŒ²ã‚„ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹æƒ…å ±ã€ç”Ÿæ´»æƒ…å ±ã«ç­”ãˆã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("AIå…ˆè¼©ãŒè€ƒãˆä¸­..."):
            user_embedding = genai.embed_content(
                model=EMBEDDING_MODEL,
                content=prompt,
                task_type="RETRIEVAL_QUERY"
            )["embedding"]
            user_embedding_np = np.array(user_embedding).astype('float32').reshape(1, -1)

            D, I = faiss_index.search(user_embedding_np, 1)
            top_similarity = 1 - (D[0][0] / 2)

            if top_similarity >= FAISS_THRESHOLD:
                retrieved_question = faq_questions[I[0][0]]
                retrieved_answer = faq_answers[I[0][0]]
                context_text = f"å‚è€ƒæƒ…å ±:
è³ªå•: {retrieved_question}
å›ç­”: {retrieved_answer}
---"
                is_unanswered = False
                source_faq = retrieved_question
            else:
                context_text = "å‚è€ƒæƒ…å ±: è©²å½“ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚
---"
                is_unanswered = True
                source_faq = "N/A (unanswered)"

            system_prompt = '''
            ã‚ãªãŸã¯å¤§å­¦ã®å­¦ç”Ÿæ”¯æ´ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã€ŒAIå…ˆè¼©ã€ã§ã™ã€‚
            ä»¥ä¸‹ã®ã€Œå‚è€ƒæƒ…å ±ã€ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§ä¸å¯§ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
            å‚è€ƒæƒ…å ±ã«è©²å½“ã™ã‚‹æƒ…å ±ãŒå…¨ããªã„å ´åˆã‚„é–¢é€£æ€§ãŒä½ã„å ´åˆã¯ã€
            ã€Œç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãã®æƒ…å ±ã«ã¤ã„ã¦ã¯ç¾åœ¨æŒã¡åˆã‚ã›ã¦ãŠã‚Šã¾ã›ã‚“ã€‚ã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚
            '''
            try:
                model = genai.GenerativeModel(GENERATION_MODEL)
                response = model.generate_content(f"{system_prompt}
{context_text}
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•:
{prompt}")
                bot_response = response.text

                if "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãã®æƒ…å ±ã«ã¤ã„ã¦ã¯ç¾åœ¨æŒã¡åˆã‚ã›ã¦ãŠã‚Šã¾ã›ã‚“" in bot_response:
                    is_unanswered = True
            except Exception as e:
                bot_response = f"å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚({e})"
                is_unanswered = True

        st.markdown(bot_response)
        st.session_state.messages.append({"role": "assistant", "content": bot_response})

        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_data = {
            "timestamp": current_time,
            "user_question": prompt,
            "bot_answer": bot_response,
            "is_unanswered": is_unanswered,
            "source_faq_question": source_faq
        }
        append_log(CHAT_LOG_FILE, log_data)

        if is_unanswered:
            unanswered_data = {
                "timestamp": current_time,
                "user_question": prompt
            }
            append_log(UNANSWERED_LOG_FILE, unanswered_data)

        st.caption(f"ï¼ˆé¡ä¼¼åº¦: {top_similarity:.2f}, æœªå›ç­”: {is_unanswered}ï¼‰")
